{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Classification Problems\n",
    "\n",
    "Made for the Data Science Workshop 2018 (African Institute for Mathematical Sciences)\n",
    "\n",
    "(extended from https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n",
      "Testing data shape :  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)\n",
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the unique numbers from the train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11ce47f60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEtCAYAAAAsgeXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cbd68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    " \n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_train[0]))\n",
    " \n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_test[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten the data\n",
    "\n",
    "In this notebook we won't be making use of the data as \"images\" but rather as long vectors of length 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is what an example in the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the data is a long vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    3.,\n",
       "         18.,   18.,   18.,  126.,  136.,  175.,   26.,  166.,  255.,\n",
       "        247.,  127.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   30.,   36.,   94.,  154.,\n",
       "        170.,  253.,  253.,  253.,  253.,  253.,  225.,  172.,  253.,\n",
       "        242.,  195.,   64.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   49.,  238.,  253.,  253.,\n",
       "        253.,  253.,  253.,  253.,  253.,  253.,  251.,   93.,   82.,\n",
       "         82.,   56.,   39.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,   18.,  219.,  253.,\n",
       "        253.,  253.,  253.,  253.,  198.,  182.,  247.,  241.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,   80.,\n",
       "        156.,  107.,  253.,  253.,  205.,   11.,    0.,   43.,  154.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,   14.,    1.,  154.,  253.,   90.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,  139.,  253.,  190.,    2.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   11.,  190.,  253.,   70.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,   35.,  241.,\n",
       "        225.,  160.,  108.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         81.,  240.,  253.,  253.,  119.,   25.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,   45.,  186.,  253.,  253.,  150.,   27.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,   16.,   93.,  252.,  253.,  187.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,  249.,  253.,\n",
       "        249.,   64.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,   46.,  130.,  183.,  253.,\n",
       "        253.,  207.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,   39.,  148.,  229.,  253.,  253.,\n",
       "        253.,  250.,  182.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,   24.,  114.,  221.,  253.,  253.,  253.,\n",
       "        253.,  201.,   78.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,   23.,   66.,  213.,  253.,  253.,  253.,  253.,\n",
       "        198.,   81.,    2.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,   18.,  171.,  219.,  253.,  253.,  253.,  253.,  195.,\n",
       "         80.,    9.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "         55.,  172.,  226.,  253.,  253.,  253.,  253.,  244.,  133.,\n",
       "         11.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,  136.,  253.,  253.,  253.,  212.,  135.,  132.,   16.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise\n",
    "\n",
    "We need to normalise the data since the values range from 0 to 255. Training NNs on data ranging between [0,1] can be easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to want our labels as one-hot vectors, which are vectors that holds mostly 0's and one 1. It's easiest to see this in a example. As a one-hot vector, the number 0 is represented as [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], and 4 is represented as [0, 0, 0, 0, 1, 0, 0, 0, 0, 0].\n",
    "\n",
    "One-hot encoded vectors allow us to map each category in our set of labels to a vector where only a single value is 1.\n",
    "\n",
    "0 maps to [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "1 maps to [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "2 maps to [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Notes on one-hot encoding: https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "num_classes = Y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(784, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "11s - loss: 0.2799 - acc: 0.9201 - val_loss: 0.1510 - val_acc: 0.9560\n",
      "Epoch 2/2\n",
      "10s - loss: 0.1110 - acc: 0.9680 - val_loss: 0.0959 - val_acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a955e80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=2, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(np.expand_dims(X_test[0], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9728/10000 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_values = np.argmax(Y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.269999999999996"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Create a neural network to classify Iris plants based on 4 features. \n",
    "\n",
    "A neural network can't output categorical labels directly. They can instead output a number which corresponds to the categorical label. Convert the column in the dataset which contains the target class categorical data using scikit learn. (hint: use the labelEncoder). Add the new data into the dataframe and drop the column with the categorical data. Confusion matrices are useful. Try and use scikit learn to get the confusion matrix for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Iris.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
